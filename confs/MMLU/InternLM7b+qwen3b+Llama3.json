{
    "model_path": {
      "main_model_path": "internlm/internlm2_5-7b-chat",
      "assist_model1_path": "Qwen/Qwen2.5-3B-Instruct",
      "assist_model2_path": "meta-llama/Meta-Llama-3-8B-Instruct"
    },
    "file_path": {
      "dev_file_path": "/data/home/username/Experiments/LLM_ensemble/Datasets/MMLU/dev+val.jsonl",
      "test_file_path": "/data/home/username/Experiments/LLM_ensemble/Datasets/MMLU/test.jsonl",
      "demon_file_path": "/data/home/username/Experiments/LLM_ensemble/Datasets/MMLU/demon.jsonl"
    },
    "prompt_template": {
      "main_model_system_template": "<s>{}",
      "assist_model1_system_template": "<s>{}",
      "assist_model2_system_template": "<s>{}",
      "instruction": "",
      "instruction_parameter": {
        "key": [
          "domain",
          "question",
          "A",
          "B",
          "C",
          "D"
        ],
        "template": "There is a single choice question about {}. Answer the question by replying A, B, C or D.\nQuestion: {}\nA. {}\nB. {}\nC. {}\nD. {}\nAnswer:\n"
      },
      "demon_parameter": {
        "key": [
          "domain",
          "question",
          "A",
          "B",
          "C",
          "D",
          "answer"
        ],
        "template": "There is a single choice question about {}. Answer the question by replying A, B, C or D.\nQuestion: {}\nA. {}\nB. {}\nC. {}\nD. {}\nAnswer:\n{}\n"
      }
    },
    "run_parameter": {
      "max_new_tokens": 1
    },
    "result_process_parameter": {
      "early_stop_string_list": [
        "\n"
      ],
      "split_key_before": [
        "Answer:\n"
      ],
      "split_key_behind": [
        "\n",
        "<|endoftext|>",
        "<unk>"
      ]
    }
  }
  